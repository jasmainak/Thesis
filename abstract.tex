\begin{changemargin}{-2.5cm}{-1.2cm}

\begin{abstract}


\begin{center}
{\Large \textbf{Apprentissage Automatique et Extrêmes pour la Détection d'Anomalies\\}}
\textbf{Nicolas Goix}
\end{center}


{\setstretch{1.0}

\paragraph{RESUME}
... \\ ... \\
\textbf{MOTS-CLEFS:} Détection d'anomalie, extrêmes multivariés, forêts aléatoires, sélection de modèles non-supervisé.

\paragraph{ABSTRACT}

{\small

Anomaly, outlier or novelty detection is not only a useful preprocessing step for training machine learning algorithms. It is also a crucial component of lots of real-world applications, from various fields like finance, insurance, telecommunication, computational biology, health or environmental sciences. Anomaly detection is also more and more relevant in the modern world, as an increasing number of autonomous systems need to be monitored and diagnosed. % -- \eg~with the rise of Internet-of-Things.
%
Important research areas in anomaly detection include the design of efficient algorithms and their theoretical study %(derived from a mathematical theory as well as heuristic-based ones), 
%the theoretical study of existing algorithms lacking from such guaranties, 
but also the evaluation of such algorithms, in particular when no labeled data is available -- as in lots of industrial setups. 
In other words, model design and study, and model selection.

In this thesis, we focuse on both of these aspects. 
In practice, anomaly detection algorithms output a real valued \emph{scoring function} on the feature space so as to quantify to which extent observations should be considered as abnormal.
%
We first propose a criterion for measuring the performance of scoring functions, alternative to the existing \emph{mass-volume curve}. %-- function outputed by anomaly detection algorithms and measuring the supposed degree of abnormality of the observations.
This criterion, refered as \emph{excess-mass curve}, aims at building scoring functions \emph{via} empirical risk minimization.


The second part of this work focuses on \emph{extreme} regions, which are of particular interest in anomaly detection. In particular, probabilistic tools borrowed from (multivariate) extreme value theory, such as the stable tail dependence function (STDF) and the angular measure, can be combined with classical anomaly detection approaches to gain in accuracy on such extreme regions.
%
%Advances in multivariate EVT are brought by
We provide non-asymptotic bounds for the estimation of the STDF, which characterizes the extreme dependence structure.
%
A statistical method that produces a (possibly sparse) representation of the extreme dependence structure is then derived from a non-parametric estimation of the angular measure on representative sets of directions. This representation can be used directly to produce a scoring function accurate on extremes regions. Non-asymptotic bounds to assess the accuracy of the estimation procedure are established.

The last part of this work is essentially heuristic-based. %compiles some limitations of previous parts, and proposes two heuristics, one from the model selection / algorithms evaluation point of view, the other from the algorithms design. %and proposes solutions to the two major drawbacks raised by the Excess-Mass and Mass-Volume curves: poor performance in practice
%
% From the model selection point of view, no empirical study has been made on Excess-Mass and Mass-Volume curves for evaluating anomaly detection algorithms without using any labels. Besides, these curves can only been estimated in small dimensions as they involve some volume computation. 
% and no study has been done on their capacity to discriminate between scoring functions with respect to ROC and PR curves when labels are used.
%If default parameters usually work well for the EVT-based scoring function we promote next, accurate
From the model selection viewpoint, an empirical study for the use of excess-mass and mass-volume curves as evaluation criteria in the absence of labeled data is derived. 
 As these curves generally cannot be well estimated in large dimension,
a methodology based on feature sub-sampling and aggregating is also described and tested, extending the use of these criteria to high-dimensional datasets and solving major drawbacks inherent to standard EM and MV curves. 
%
From the model design point of view,
an efficient algorithm based on random forests producing accurate scoring functions is proposed. It builds on a natural extention of standard splitting criteria to the one-class setting. This structural generalizion of random forests to one-class classification produces competitive scoring functions, according to an extensive benchmmark which includes many state-of-the-art anomaly detection algorithms commonly used in industrial setups.

\textbf{KEYWORDS:} Anomaly detection, multivariate extremes, random forests, unsupervised model selection
}

}

\end{abstract}
\end{changemargin}
