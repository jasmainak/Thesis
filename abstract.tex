\paragraph{Abstract}

Anomaly, outlier or novelty detection is not only a useful preprocessing step for training machine learning algorithms. It is also a crucial component of lots of real-world applications, from various fields like finance, insurance, telecommunication, computational biology, health or environmental sciences. Anomaly detection is also more and more relevant in the modern world, as an increasing number of autonomous systems need to be monitored and diagnosed -- \eg~with the rise of Internet-of-Things.

Important research areas in anomaly detection include the design of efficient algorithms (derived from a mathematical theory as well as heuristic-based ones), 
%the theoretical study of existing algorithms lacking from such guaranties, 
and the evaluation of such anomaly detection when -- as in much of industrial setups -- no labeled data is available. 
In other words, model design and selection.
In practice, anomaly detection algorithm output a real valued \emph{scoring function} on the feature space so as to quantify to which extent observations should be considered as abnormal.

In this thesis, we focuse on both of these aspects. We first propose a criterion for measuring the performance of scoring functions, more convenient than the existing \emph{Mass-Volume curve}. %-- function outputed by anomaly detection algorithms and measuring the supposed degree of abnormality of the observations.
This criterion, refered as \emph{Excess-Mass curve}, aims at building scoring functions \emph{via} empirical risk minimization (ERM).
Two limitations of Excess-Mass and Mass-Volume curves are the following.
While theoretical guaranties are also derived, more work is needed for it to be efficient in practice, particularly concerning the choice of the functional class on which the criterion is optimized (which is typically the class of stepwise functions on very simple sets). When used as evaluation criteria, these criteria cannot be used in large dimension.


The second part of this work focuses on \emph{extreme} regions, which are of particular interest in anomaly detection. In particular, probabilistic tools borrowed from (multivariate) Extreme Value Theory (EVT), such as the stable tail dependence function (STDF) and the angular measure, can be combined with classical anomaly detection approaches to gain in accuracy on such extreme regions.
%
Advances in multivariate EVT are brought by providing non-asymptotic bounds for the estimation of the STDF, which characterizes the extreme dependence structure.
%
Then a statistical method that produces a (possibly sparse) representation of the dependence structure of extremes is derived from an estimate of the angular measure. This representation can be used directly to produce a scoring function accurate on extremes regions.
Non-asymptotic bounds to assess the accuracy of the estimation procedure are established.
A drawback of this approach is that performance depends on hyper-parameters. They cannot be settled using the theoretical bounds as the latter include a non-explicit bias term. Most of the time, they cannot be settled from the data either, as often no labeled data is available for \eg~cross-validation.


The last part of this work is heuristic-based. %and proposes solutions to the two major drawbacks raised by the Excess-Mass and Mass-Volume curves: poor performance in practice
First, it proposes an empirical study for the use of Excess-Mass and Mass-Volume curves as evaluation criteria in the absence of labeled data.
As they generally cannot be well estimated in large dimension, a methodology based on feature sub-sampling and aggregating is also described and tested, extending the use of these criteria to high-dimensional datasets and solving major drawbacks inherent to standard EM and MV curves. 

Second, a natural simple methodology is proposed to extend random forests splitting criteria to the one-class setting.
This structural generalizion of random forests to one-class classification produces efficient scoring functions, according to an extensive benchmmark which includes many state-of-the-art anomaly detection algorithm commonly used in industrial setups.



% Assessing the probability of occurrence of extreme events is a crucial issue in various fields like
% finance, insurance, telecommunication or environmental sciences. In a multivariate framework, the
% tail dependence is characterized by the so-called stable tail dependence function ( STDF ). Learning
% this structure is the keystone of multivariate extremes. Although extensive studies have proved con-
% sistency and asymptotic normality for the empirical version of the STDF , non-asymptotic bounds
% are still missing. The main purpose of this paper is to fill this gap. Taking advantage of adapted
% VC-type concentration inequalities, upper bounds are derived with expected rate of convergence in
% O(k −1/2 ). The concentration tools involved in this analysis rely on a more general study of max-
% imal deviations in low probability regions, and thus directly apply to the classification of extreme
% data.


% Extremes play a special role in Anomaly Detec-
% tion. Beyond inference and simulation purposes,
% probabilistic tools borrowed from Extreme Value
% Theory (EVT), such as the angular measure, can
% also be used to design novel statistical learning
% methods for Anomaly Detection/ranking. This
% paper proposes a new algorithm based on mul-
% tivariate EVT to learn how to rank observations
% in a high dimensional space with respect to their
% degree of ‘abnormality’. The procedure relies on
% an original dimension-reduction technique in the
% extreme domain that possibly produces a sparse
% representation of multivariate extremes and al-
% lows to gain insight into the dependence struc-
% ture thereof, escaping the curse of dimensional-
% ity. The representation output by the unsuper-
% vised methodology we propose here can be com-
% bined with any Anomaly Detection technique tai-
% lored to non-extreme data. As it performs lin-
% early with the dimension and almost linearly in
% the data (in O(dn log n)), it fits to large scale
% problems. The approach in this paper is novel in
% that EVT has never been used in its multivariate
% version in the field of Anomaly Detection



% Capturing the dependence structure of multivariate extreme events is a major
% concern in many fields involving the management of risks stemming from mul-
% tiple sources, e.g. portfolio monitoring, insurance, environmental risk man-
% agement and anomaly detection. One convenient (nonparametric) charac-
% terization of extreme dependence in the framework of multivariate Extreme
% Value Theory (EVT) is the angular measure, which provides direct informa-
% tion about the probable ’directions’ of extremes, that is, the relative con-
% tribution of each feature/coordinate of the ‘largest’ observations. Modeling
% the angular measure in high dimensional problems is a major challenge for
% the multivariate analysis of rare events. The present paper proposes a novel
% methodology aiming at exhibiting a sparsity pattern within the dependence
% structure of extremes. This is achieved by estimating the amount of mass
% spread by the angular measure on representative sets of directions, corre-
% sponding to specific sub-cones of R d + . This dimension reduction technique
% paves the way towards scaling up existing multivariate EVT methods. Be-
% yond a non-asymptotic study providing a theoretical validity framework for
% our method, we propose as a direct application a –first– Anomaly Detec-
% tion algorithm based on multivariate EVT. This algorithm builds a sparse
% ‘normal profile’ of extreme behaviours, to be confronted with new (possibly
% abnormal) extreme observations. Illustrative experimental results provide
% strong empirical evidence of the relevance of our approach.


% When sufficient labeled data are available, classical criteria based on Receiver
% Operating Characteristic (ROC) or Precision-Recall (PR) curves can be used to
% compare the performance of unsupervised anomaly detection algorithms. However,
% in many situations, few or no data are labeled. This calls for alternative criteria one
% can compute on non-labeled data. In this paper, two criteria that do not require
% labels are empirically shown to discriminate accurately (w.r.t. ROC or PR based
% criteria) between algorithms. These criteria are based on existing Excess-Mass
% (EM) and Mass-Volume (MV) curves, which generally cannot be well estimated in
% large dimension. A methodology based on feature sub-sampling and aggregating is
% also described and tested, extending the use of these criteria to high-dimensional
% datasets and solving major drawbacks inherent to standard EM and MV curves.


% andom Forests (RFs) are strong machine learning tools for classification and
% regression. However, they remain supervised algorithms, and no extension of RFs
% to the one-class setting has been proposed, except for techniques based on second-
% class generation. This paper fills this gap by proposing a natural methodology to
% extend standard splitting criteria to the one-class setting, structurally generalizing
% to one-class classification. Our model is consistent with the two-class framework
% from which our approach can be recovered, considering the asymptotic behavior of
% an adaptive outliers generating process. We also present an extensive benchmark
% of seven state-of-the-art anomaly detection algorithms. This demonstrates the
% empirical relevance of our approach.


\paragraph{Résumé}