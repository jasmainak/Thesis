\contentsline {chapter}{List of Contributions}{iii}{dummy.1}
\contentsline {chapter}{List of Figures}{xi}{dummy.2}
\contentsline {chapter}{List of Tables}{xiii}{dummy.3}
\contentsline {chapter}{\numberline {1}Summary}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Introduction}{1}{section.1.1}
\contentsline {paragraph}{Notations}{2}{section.1.1}
\contentsline {section}{\numberline {1.2}Anomaly Detection, Anomaly Ranking and Scoring Functions}{2}{section.1.2}
\contentsline {section}{\numberline {1.3}M-estimation and criteria for scoring functions}{5}{section.1.3}
\contentsline {subsection}{\numberline {1.3.1}Minimum Volume sets}{5}{subsection.1.3.1}
\contentsline {subsection}{\numberline {1.3.2}Mass-Volume curve}{6}{subsection.1.3.2}
\contentsline {subsection}{\numberline {1.3.3}The Excess-Mass criterion}{8}{subsection.1.3.3}
\contentsline {section}{\numberline {1.4}Accuracy on extreme regions}{10}{section.1.4}
\contentsline {subsection}{\numberline {1.4.1}Extreme Values Analysis through STDF estimation}{10}{subsection.1.4.1}
\contentsline {paragraph}{Preliminaries.}{10}{subsection.1.4.1}
\contentsline {paragraph}{Learning the dependence structure of rare events.}{11}{subsection.1.4.1}
\contentsline {subsection}{\numberline {1.4.2}Sparse Representation of Multivariate Extremes}{12}{subsection.1.4.2}
\contentsline {section}{\numberline {1.5}Heuristic-based approaches}{15}{section.1.5}
\contentsline {subsection}{\numberline {1.5.1}Evaluation of AD algorithms}{15}{subsection.1.5.1}
\contentsline {subsection}{\numberline {1.5.2}One-Class Random Forests}{17}{subsection.1.5.2}
\contentsline {section}{\numberline {1.6}Scikit-learn contributions}{20}{section.1.6}
\contentsline {section}{\numberline {1.7}Conclusion and Scientific Output}{21}{section.1.7}
\contentsline {paragraph}{Context of this work.}{22}{section.1.7}
\contentsline {paragraph}{Outline of the thesis.}{22}{section.1.7}
\contentsline {part}{I\hspace {1em}Preliminaries}{25}{part.1}
\contentsline {chapter}{\numberline {2}Concentration Inequalities from the Method of bounded differences}{27}{chapter.2}
\contentsline {section}{\numberline {2.1}Two fundamental results}{27}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Preliminary definitions}{27}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Inequality for Bounded Random Variables}{28}{subsection.2.1.2}
\contentsline {subsection}{\numberline {2.1.3}Bernstein-type Inequality (with variance term)}{30}{subsection.2.1.3}
\contentsline {section}{\numberline {2.2}Popular Inequalities}{31}{section.2.2}
\contentsline {section}{\numberline {2.3}Connections with Statistical Learning and VC theory}{34}{section.2.3}
\contentsline {section}{\numberline {2.4}Sharper VC-bounds through a Bernstein-type inequality}{37}{section.2.4}
\contentsline {chapter}{\numberline {3}Extreme Value Theory}{41}{chapter.3}
\contentsline {paragraph}{Notation reminder}{41}{chapter.3}
\contentsline {section}{\numberline {3.1}Univariate Extreme Value Theory}{42}{section.3.1}
\contentsline {section}{\numberline {3.2}Extension to the Multivariate framework}{44}{section.3.2}
\contentsline {chapter}{\numberline {4}Background on classical Anomaly Detection algorithms}{49}{chapter.4}
\contentsline {section}{\numberline {4.1}What is Anomaly Detection?}{49}{section.4.1}
\contentsline {section}{\numberline {4.2}Three efficient Anomaly Detection Algorithms}{51}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}One-class SVM}{51}{subsection.4.2.1}
\contentsline {subsection}{\numberline {4.2.2}Local Outlier Factor algorithm}{52}{subsection.4.2.2}
\contentsline {subsection}{\numberline {4.2.3}Isolation Forest}{54}{subsection.4.2.3}
\contentsline {section}{\numberline {4.3}Examples through scikit-learn}{54}{section.4.3}
\contentsline {subsection}{\numberline {4.3.1}What is scikit-learn?}{54}{subsection.4.3.1}
\contentsline {subsection}{\numberline {4.3.2}LOF examples}{56}{subsection.4.3.2}
\contentsline {subsection}{\numberline {4.3.3}Isolation Forest examples}{57}{subsection.4.3.3}
\contentsline {subsection}{\numberline {4.3.4}Comparison examples}{59}{subsection.4.3.4}
\contentsline {part}{II\hspace {1em}An Excess-Mass based Performance Criterion}{63}{part.2}
\contentsline {chapter}{\numberline {5}On Anomaly Ranking and Excess-Mass Curves}{65}{chapter.5}
\contentsline {section}{\numberline {5.1}Introduction}{65}{section.5.1}
\contentsline {section}{\numberline {5.2}Background and related work}{67}{section.5.2}
\contentsline {section}{\numberline {5.3}The Excess-Mass curve}{69}{section.5.3}
\contentsline {section}{\numberline {5.4}A general approach to learn a scoring function}{72}{section.5.4}
\contentsline {section}{\numberline {5.5}Extensions - Further results}{75}{section.5.5}
\contentsline {subsection}{\numberline {5.5.1}Distributions with non compact support}{75}{subsection.5.5.1}
\contentsline {subsection}{\numberline {5.5.2}Bias analysis}{77}{subsection.5.5.2}
\contentsline {section}{\numberline {5.6}Simulation examples}{79}{section.5.6}
\contentsline {section}{\numberline {5.7}Conclusion}{79}{section.5.7}
\contentsline {section}{\numberline {5.8}Illustrations}{81}{section.5.8}
\contentsline {section}{\numberline {5.9}Detailed Proofs}{81}{section.5.9}
\contentsline {part}{III\hspace {1em}Accuracy on Extreme Regions}{89}{part.3}
\contentsline {chapter}{\numberline {6}Learning the dependence structure of rare events: a non-asymptotic study}{91}{chapter.6}
\contentsline {section}{\numberline {6.1}Introduction}{91}{section.6.1}
\contentsline {section}{\numberline {6.2}Background on the stable tail dependence function}{92}{section.6.2}
\contentsline {section}{\numberline {6.3}A VC-type inequality adapted to the study of low probability regions}{93}{section.6.3}
\contentsline {paragraph}{Classification of Extremes}{95}{theorem.6.3.4}
\contentsline {section}{\numberline {6.4}A bound on the STDF}{96}{section.6.4}
\contentsline {section}{\numberline {6.5}Discussion}{102}{section.6.5}
\contentsline {chapter}{\numberline {7}Sparse Representation of Multivariate Extremes}{103}{chapter.7}
\contentsline {section}{\numberline {7.1}Introduction}{103}{section.7.1}
\contentsline {subsection}{\numberline {7.1.1}Context: multivariate extreme values in large dimension}{103}{subsection.7.1.1}
\contentsline {subsection}{\numberline {7.1.2}Application to Anomaly Detection}{106}{subsection.7.1.2}
\contentsline {section}{\numberline {7.2}Multivariate EVT Framework and Problem Statement}{107}{section.7.2}
\contentsline {subsection}{\numberline {7.2.1}Statement of the Statistical Problem}{108}{subsection.7.2.1}
\contentsline {subsection}{\numberline {7.2.2}Regularity Assumptions}{111}{subsection.7.2.2}
\contentsline {section}{\numberline {7.3}A non-parametric estimator of the subcones' mass : definition and preliminary results}{113}{section.7.3}
\contentsline {subsection}{\numberline {7.3.1}A natural empirical version of the exponent measure mu}{113}{subsection.7.3.1}
\contentsline {subsection}{\numberline {7.3.2}Accounting for the non asymptotic nature of data: epsilon-thickening.}{114}{subsection.7.3.2}
\contentsline {subsection}{\numberline {7.3.3}Preliminaries: uniform approximation over a VC-class of rectangles}{115}{subsection.7.3.3}
\contentsline {subsection}{\numberline {7.3.4}Bounding empirical deviations over thickened rectangles}{119}{subsection.7.3.4}
\contentsline {subsection}{\numberline {7.3.5}Bounding the bias induced by thickened rectangles}{120}{subsection.7.3.5}
\contentsline {subsection}{\numberline {7.3.6}Main result}{120}{subsection.7.3.6}
\contentsline {section}{\numberline {7.4}Application to Anomaly Detection }{124}{section.7.4}
\contentsline {subsection}{\numberline {7.4.1}Extremes and Anomaly Detection.}{124}{subsection.7.4.1}
\contentsline {subsection}{\numberline {7.4.2}DAMEX Algorithm: Detecting Anomalies among Multivariate Extremes}{124}{subsection.7.4.2}
\contentsline {section}{\numberline {7.5}Experimental results}{128}{section.7.5}
\contentsline {subsection}{\numberline {7.5.1}Recovering the support of the dependence structure of generated data}{128}{subsection.7.5.1}
\contentsline {subsection}{\numberline {7.5.2}Sparse structure of extremes (wave data)}{129}{subsection.7.5.2}
\contentsline {subsection}{\numberline {7.5.3}Application to Anomaly Detection on real-world data sets}{130}{subsection.7.5.3}
\contentsline {section}{\numberline {7.6}Conclusion}{134}{section.7.6}
\contentsline {section}{\numberline {7.7}Technical proofs}{135}{section.7.7}
\contentsline {subsection}{\numberline {7.7.1}Proof of Lemma \ref {jmva:lem:equivalence}}{135}{subsection.7.7.1}
\contentsline {subsection}{\numberline {7.7.2}Proof of Lemma \ref {jmva:lem:g-alpha}}{135}{subsection.7.7.2}
\contentsline {subsection}{\numberline {7.7.3}Proof of Proposition \ref {jmva:prop:g}}{137}{subsection.7.7.3}
\contentsline {subsection}{\numberline {7.7.4}Proof of Lemma \ref {jmva:lemma_simplex}}{141}{subsection.7.7.4}
\contentsline {subsection}{\numberline {7.7.5}Proof of Remark\nobreakspace {}\ref {jmva:rk:optim}}{143}{subsection.7.7.5}
\contentsline {section}{\numberline {7.8}Experiments curves}{143}{section.7.8}
\contentsline {part}{IV\hspace {1em}Efficient heuristic-based approaches}{145}{part.4}
\contentsline {chapter}{\numberline {8}How to Evaluate the Quality of Unsupervised Anomaly Detection Algorithms?}{147}{chapter.8}
\contentsline {chapter}{\numberline {9}One Class Splitting Criteria for Random Forests with Application to Anomaly Detection}{149}{chapter.9}
\contentsline {section}{\numberline {9.1}Introduction}{149}{section.9.1}
\contentsline {chapter}{\numberline {10}Conclusion \& Perspectives}{151}{chapter.10}
\contentsline {chapter}{Bibliography}{153}{dummy.4}
\contentsline {paragraph}{Abstract}{162}{appendix*.36}
\contentsline {paragraph}{R\IeC {\'e}sum\IeC {\'e}}{162}{appendix*.36}
