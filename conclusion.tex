In this thesis, we have addressed three important limitations of existing anomaly detection litterature. The problem of evaluating algorithm in the case of unlabeled data, the problem of extending the use of random forests to one-class classification, and the problem of being accurate on low probability regions.

Our first contribution was to proposed an unsupervised performance criterion, in order to compare scoring functions and to pick one eventually.
%
This excess-mass based criterion resolved some of the drawbacks inherent to the previous mass-volume curve criterion. But the main drawback, estimating a volume in the input space, still remains. This infortunately constitutes a strong setback for its use in a high dimensional framework, if no prior knowledge on the form of these volume to estimate is available. In such a context, classical evaluation approaches must be used, such as ROC or Precision-Recall curves, which assume that at least a small proportion of data is labelled.
Practical unsupervised evaluation criteria still remaining a major challenge (specially under the constraint of scaling with dimension), we studied empirically the use of EM or MV as evaluation criteria and proposed a way to scale their use to high dimensions.

As trying to minimize EM or MV criteria does not produce performant algorithms in practice, we introduced a One Class Random Forest algorithm which structurally extend RFs to one-class classification.
 
Finally, we proposed to focus on extreme regions to gain in accuracy when building scoring functions. An intermediary step was % our fourth contribution, which
to
studies non-asymptotic behavior of an extreme value copula, the stable tail dependence function. We brought new bounds to control the error of its natural empirical version as well as a practical framework for deriving VC-type bounds on low-probability regions.
%
This framework also allows to approach a particular prediction context, namely where the objective is to learn a classifier (or a regressor) that has good properties on low-probability regions.
%
% 
% The previous framework of maximal deviation in low-probability regions also
% opened the road to the statistical ground on which our fifth contribution lies. The latter designs a method that produces a scoring function based on a (possibly sparse) representation of the dependence structure of extremes. Non-asymptotic bounds are derived to assess the accuracy of the estimation procedure, and empirical studies show the relevance of this approach, which is suitable for the treatment of real word large-scale learning problems due to its moderate complexity.
%
Besides, as we exhibit a sparsity pattern in multivariate extremes, it can be used as a preprocessing step to scale up multivariate extreme values modeling to high dimensional settings, which is currently one of the major challenges in multivariate EVT.


%
Staying in the scope of multivariate extremes, the non-asymptotic bounds in the two main results contain separated bias terms corresponding to the (distribution-dependent) convergence speed to the asymptotic behavior, which are not controlled explicitly.
A possible future direction is to make an additional hypothesis
of  `second order regular variation'  \citep[see \emph{e.g.}][]{deHaan1996}
in order to express these bias terms, and possibly to refine the results.
With such explicit bounds, parameters of the Damex algorithm (third contribution) could be chosen optimally as the ones minimizing the obtained bound.

From the scope of one-class random forests, a possible research direction would be to develop theoretical grounds for the level sets estimation procedure. Classical studies from the two-class framework should be adapted to one-class classification.
% As a last contribution (of incremental nature), two classical AD algorithms have been implemented and merged on scikit-learn. They are used in this dissertation for empirical comparison to attest the relevance of the forementionned approach.
